{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91055147-71e8-4764-98d2-01b8ae50a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import dotenv_values\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from functools import wraps\n",
    "\n",
    "# Loading enviroment variables\n",
    "CONFIG = dotenv_values(\".env\")\n",
    "if not CONFIG:\n",
    "    CONFIG = os.environ\n",
    "\n",
    "# Log the name of the function that is executed\n",
    "def logger(fn):\n",
    "    from datetime import datetime, timezone\n",
    "\n",
    "    @wraps(fn)\n",
    "    def inner(*args, **kwargs):\n",
    "        called_at = datetime.now(timezone.utc)\n",
    "        print(f\">>> Running {fn.__name__!r} function. Logged at {called_at}\")\n",
    "        to_execute = fn(*args, **kwargs)\n",
    "        print(f\">>> Function: {fn.__name__!r} executed. Logged at {called_at}\")\n",
    "        return to_execute\n",
    "\n",
    "    return inner\n",
    "    \n",
    "# Connect to Postgres database\n",
    "@logger\n",
    "def connect_db():\n",
    "    print(\"\\nConnecting to DB\\n\")\n",
    "    connection_uri = \"postgresql+psycopg2://{}:{}@{}:{}\".format(\n",
    "        CONFIG[\"POSTGRES_USER\"],\n",
    "        CONFIG[\"POSTGRES_PASSWORD\"],\n",
    "        CONFIG[\"POSTGRES_HOST\"],\n",
    "        CONFIG[\"POSTGRES_PORT\"],\n",
    "    )\n",
    "\n",
    "    engine = create_engine(connection_uri, pool_pre_ping=True)\n",
    "    engine.connect()\n",
    "    return engine\n",
    "\n",
    "# Transform the data\n",
    "@logger\n",
    "def transform(file_name, sheet):\n",
    "    # Read raw file\n",
    "    df = pd.read_excel(file_name, sheet_name=sheet)\n",
    "    \n",
    "    # Transform raw data in desire schema\n",
    "    df.columns = ['Combustível', 'Ano', 'Região', 'uf', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', 'Total']\n",
    "    df = df.melt(id_vars = ['Combustível', 'Ano', 'Região', 'uf'])\n",
    "    df = df.loc[df['variable'] != 'Total']\n",
    "    df = df.rename(columns = {'value': 'volume'})\n",
    "    df['year_month'] = df['Ano'].astype(str) + '-' + df['variable']\n",
    "    df['year_month'] = pd.to_datetime(df['year_month'])\n",
    "    df[['product','unit']] = df['Combustível'].str.rsplit(\" (\", n=1, expand=True)\n",
    "    df['unit'] = df['unit'].map(lambda x: x.rstrip(')'))\n",
    "    df = df.drop(labels = ['Combustível','variable', 'Região', 'Ano'], axis=1)\n",
    "    df.insert(0, 'created_at', pd.to_datetime('now').replace(microsecond=0))\n",
    "    df = df[['year_month', 'uf', 'product', 'unit', 'volume', 'created_at']]\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "# Load the data to Postgres DB\n",
    "@logger\n",
    "def load(df, engine, table_name):\n",
    "    df.to_sql(table_name, engine, if_exists=\"replace\")\n",
    "    check_table_exists(table_name, engine)\n",
    "\n",
    "# Check if table exist in DB\n",
    "@logger\n",
    "def check_table_exists(table_name, engine):\n",
    "    if table_name in inspect(engine).get_table_names():\n",
    "        print(f\"\\n{table_name!r} exists in the DB! Replacing...\\n\")\n",
    "    else:\n",
    "        print(f\"\\n{table_name} does not exist in the DB! Creating...\\n\")\n",
    "\n",
    "# Run ETL pipeline\n",
    "@logger\n",
    "def etl():    \n",
    "    file_name = 'raw' + '/' + 'raw_data.xlsx'\n",
    "    \n",
    "    sheet_1 = \"DPCache_m3\"\n",
    "    table_name_1 = \"sales_oil_derivative\"\n",
    "    sheet_2 = \"DPCache_m3_2\"\n",
    "    table_name_2 = \"sales_diesel\"\n",
    "    \n",
    "    engine = connect_db()\n",
    "    \n",
    "    df1 = transform(file_name, sheet_1)\n",
    "    load(df1, engine, table_name_1)\n",
    "    \n",
    "    df2 = transform(file_name, sheet_2)\n",
    "    load(df2, engine, table_name_2)\n",
    "    \n",
    "    print('\\nEnd of process, run pd.read_sql(f\"SELECT * FROM table_name  LIMIT 10\", engine) to see the results.\\n')\n",
    "\n",
    "# Run the ETL process\n",
    "etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fe569-04e6-4fa6-bef9-f31df2fc4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = connect_db()\n",
    "pd.read_sql(f\"SELECT * FROM sales_oil_derivative LIMIT 10\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4baf1f-f703-43cc-b630-e73cc0bd7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = connect_db()\n",
    "pd.read_sql(f\"SELECT * FROM sales_diesel LIMIT 10\", engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
